
% ===========================================================================
% Title:
% ---------------------------------------------------------------------------
% to create Type I fonts type "dvips -P cmz -t letter <filename>"
% ===========================================================================
\documentclass[11pt]{article}       %--- LATEX 2e base
\usepackage{latexsym}               %--- LATEX 2e base
%---------------- Wide format -----------------------------------------------
\textwidth=6in \textheight=9in \oddsidemargin=0.25in
\evensidemargin=0.25in \topmargin=-0.5in
%--------------- Def., Theorem, Proof, etc. ---------------------------------
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{property}{Property}
\newtheorem{observation}{Observation}
\newtheorem{fact}{Fact}
\newenvironment{proof}           {\noindent{\bf Proof.} }%
                                 {\null\hfill$\Box$\par\medskip}
%--------------- Algorithm --------------------------------------------------
\newtheorem{algX}{Algorithm}
\newenvironment{algorithm}       {\begin{algX}\begin{em}}%
                                 {\par\noindent --- End of Algorithm ---
                                 \end{em}\end{algX}}
\newcommand{\step}[2]            {\begin{list}{}
                                  {  \setlength{\topsep}{0cm}
                                     \setlength{\partopsep}{0cm}
                                     \setlength{\leftmargin}{0.8cm}
                                     \setlength{\labelwidth}{0.7cm}
                                     \setlength{\labelsep}{0.1cm}    }
                                  \item[#1]#2    \end{list}}
                                 % usage: \begin{algorithm} \label{xyz}
                                 %        ... \step{(1)}{...} ...
                                 %        \end{algorithm}
%--------------- Figures ----------------------------------------------------
\usepackage{graphicx}

\newcommand{\includeFig}[3]      {\begin{figure}[htb] \begin{center}
                                 \includegraphics
                                 [width=4in,keepaspectratio] %comment this line to disable scaling
                                 {#2}\caption{\label{#1}#3} \end{center} \end{figure}}
                                 % usage: \includeFig{label}{file}{caption}


% ===========================================================================
\begin{document}
% ===========================================================================

% ############################################################################
% Title
% ############################################################################

\title{GPU-powered outlier detection on stream data}


% ############################################################################
% Author(s) (no blank lines !)
\author{
% ############################################################################
Kangqing YU\\
School of Computer Science\\
Carleton University\\
Ottawa, Canada K1S 5B6\\
{\em kangqingyu@cmail.carleton.ca}
% ############################################################################
} % end-authors
% ############################################################################

\maketitle

% ############################################################################
% Abstract
% ############################################################################
\begin{abstract}
Outlier detection has become an increasing challenging task in modern applications due to the fact that the data may come in the form of streams rather than statically as it was before. A lot of algorithms have been modified so that they can work in the streaming environment. Among all of them, a very popular technique called \textit{sliding window} is used, which only keep a portion of streaming data in memory and detect outliers only among all of those data. A main drawback with this approach is that the decision of outliers is only based on the data in current window and historical data are simply dropped and not considered in decision making of outlier data in current window. Therefore, this method fails to address the nature of \textit{concerpt drift} in data streams. Another challenge is that since the data may come at a very high rates and it is impossible to store all data in memory, the decision should be made in a timely manner with only one pass over data stream. This will pose a very harsh requirement in computational power and in most case, it is impossible for CPU programming to achieve. In this project, I purposed a novel solution to detect outliers in streaming environment, powered by GPU, based on a very efficient classical algorithm called LOF(Local Outlier Factor) to address the increasing challenge of outlier detection over continuous data streams. The proposed method, named LOF\_GPU is able to address the \textit{concerpt drift} in data streams, as well as detecting outliers in high-dimensional, high-rates data streams and produces timely results without compromising performances. Since the LOF algorithm is very computational expensive, very few works(almost none) have been conducted to extend the algorithm to work in streaming environment. As far as I know, the solution I purposed is the first algorithm that try to modify the LOF algorithm in the streaming environment and it is also the first parallel implementation of LOF algorithm in the streaming context.
\end{abstract}


% ############################################################################
\section{Introduction} \label{intro}
% ############################################################################

In recent years, parallel computing has drawn a tremendous amount of attentions and it is becoming a main stream for many applications including data science, biochemistry, medical etc. Among all different categories of parallel computing, one which is really easy to achieve from the hardware perspective is GPU(Graphics Processing Units) programming, which takes advantages of Graphical Processor Unit to accelerate the performance for many tasks which are considered computational expensive in CPU(Central Processing Unit). 
There are two major frameworks(libraries) that are widely used for GPU programming. One of them is OpenCL\footnote{https://www.khronos.org/opencl/}, which is a cross-platform open source frameworks for GPU programming maintained by khronos. The other is called CUDA(Compute Unified Device Architecture)\footnote{https://developer.nvidia.com/} that are designed specifically based on the architecture of NVIDIA graphics cards. Throughout this project, I will use CUDA as the programming framework for GPU acceleration on outlier detection task.  

An outlier in a dataset is a data point that is considerably different from the rest of the data as if it is generated by a different mechanism\cite{7516110}. Applications of outlier detections vary in numerous fields, including fraud detection, network intrusion detection, medical image screening, environment monitoring etc. A stream environment is where data come constantly at a high volume and may change over time. This can impose a very high requirement for computation power as decisions need to be made in real time within limited amount of time among all data. In addition to that, since the applications do not have random access to the underlying data in the streaming environment, when building an application that process data stream, these three key characteristics of data stream need to be taken into consideration: uncertainty, transiency, and incompleteness\cite{Sadik:2011:OOD:2076623.2076635}. Uncertainty means the data distribution of the model may change over the time as new data coming in a unpredictible way. This term is sometimes known as \textit{concept drift} in some literatures. Dealing with concept drift is a main challenge in most streaming applications. Transiency means it is not possible to store the entire dataset from data stream in the memory. The data can only be accessed in one pass and when it is processed, it should be deleted from memory. Completeness assume that the data will come indefinitely and they will never stop. These all make outlier detection in data streams extremely challenging from both algorithms and hardware perspective. 

To be more specific, suppose you have a data stream that keeps coming indefinitely, at one time $t_{i}$, you identify object $o_{k}$ as being outlierness in the current window. And after some time $W$ at time $t{i} + W$ when the whole recent history is considered, object $o_{k}$ may become an inliner.  And vice versa. This can be illustrate in Figure \ref{fig:evolving}

\includeFig{fig:evolving}{Figures/evolving-data}{Evolving 2D data stream}

In this project, I developed an novel, modified version of \textit{Local Outlier Factor} algorithm, LOF\_GPU where an outlier decision is made not only based the data points in the current data window, but also taking consideration of historical data without the necessity storing the entire dataset in the secondary memory. In doing so, I kept a statistical binned summary of all the observed data to help making decisions on outlier for data points within current processing window, and gradually fade away the impact on the obsolete data when making decisions on current data. And thus the proposed algorithm should provide a more accurate results compared to the widely used sliding window approach. 

Note that most density-based approaches in outlier detection, including LOF, despite being accurate, are notorious of being computational expensive. And therefore, it is almost impossible to detect outliers with high volume, high speed data streams without introducing parallelism. Other computational in-expensive algorithms exists but they either need to sacrifice on the accuracy or assuming fixed distribution over the underlying data, which fails to capture the nature of \textit{concerpt drift} in data streams. The LOF method is purely based on calculating the density of data point compared with its neighbourhood, where density is measured based on the reachability within its K nearest neighbours. The GPU is used to accelerate the computation time in order to provide timely results to keep up with tine high input rate of streaming data.

%\ref{proa} give a details explaination on the algorithm

The accuracy of the result in this method is compared with another GPU accelerated approach, SOD\_GPU as proposed in \cite{7516110}, which is based on \textit{kernel density estimator}. And the speedup on performance is compared with distance-based method based on sliding window, which runs in a multi-core CPU to further illustrate that LOF\_GPU can practically be used in a streaming environment to detect outliers at a high rate of data volume where it is otherwise incapable to handle by CPU. 


% ############################################################################
\section{Literature Review} \label{litrev}
% ############################################################################

A lot of techniques have been introduced in last decades to solve the outlier detection problem. And these techniques can be briefly summarized into three different categories: 

\begin{enumerate}
  \item Supervised approaches
  \item Semi-supervised approaches
  \item Unsupervised approaches
\end{enumerate}

Supervised approaches typically require building a prediction model for rare events based on manually labelled data(the training set), and use it to classify new event based on the learnt model\cite{Joshi:2001:MNH:376284.375673,sup02}. In other words, the outlier problem in this case becomes a classification problem where we are only interested in the minority class whose data deviate largely from the rest. The main problem with this approach is that in order to ensure accuracy, a large number of labelled data need to be generated which is unpractical in most cases 
Compared to supervised approaches, Semi-supervised approaches\cite{Basu:2004:PFS:1014052.1014062,semi-sup02} only require a small number of training data with some unlabeled data to obtain better predictions. One approach introduced by Jing Gao et all.\cite{Gao:2006:SOD:1141277.1141421} takes advantage of K-mean clustering in unsupervised learning by adding penalties to the objective function for mislabelled data points and optimize the overall objective function. 

Although some of those techniques may generate very promising results, they work well only in static data and typically don't fit into the context of dynamic streaming environment. In other words, both supervised and semi-supervised methods will assume that they will have \textit{random access} to the underlying data while this is not possible for streaming data when you can only have portion of it at one time and they also fails to address the problem of the potential change of data distribution.

In contrast, unsupervised learning methods don't require labelled input and typically don't assume a fixed data distribution as the model can be dynamically built based on variations of data. Many best-known techniques of outlier detection fall into this category and based on the context, they can mostly be classified into two categories: \textbf{Unsupervised outlier detection on static data} and \textbf{Unsupervised outlier detection on streaming data}. 

\textbf{Distance-based outlier detection} was among the very first outlier detection method introduced by Knorr and Ng\cite{EKnorr:1998}. It calculates the pair-wise Euclidian Distance between all data and if one data point has less than $k$ neighbors within distance $R$, it is considered an outlier. 

There are some variants of the static distance-based approaches, and their ideas are quite similar. For instance, Ramaswamy et all.\cite{Ramaswamy:2000:EAM:342009.335437} purposed a method where an outlier is defined by considering the total number of objects whose distance to its $k^{th}$ nearest neighbor is smaller than itself. Angiulli and Pizzuti\cite{1377172} introduced a method where an outlier is defined by taking into account of the sum of the distances from $1^st$ up to the $k^{th}$ nearest neighbors. These methods are sometimes referred as KNN and it should be noted that it is different from the term KNN in supervised machine learning. 

\textbf{Density-based approach} is another way to detect outlier on static data. The basic idea is to assign a degree of being outlier(a score) based on the density of local neighbourhood, given some predefined restrictions. A popular example of this approach is Local Outlier Factor(LOF) algorithm\cite{Breunig:2000:LID:342009.335388}, which is what this proposed algorithm is based on, use the concept called \textit{reachability} to coin the density of data point. Another popular density-based outlier detection method is called LOCI(Local Correlation Integral)\cite{1260802}

\textbf{Statistics approach} is another way to perform outlier detection on data with random access without requiring expensive computational resources. It is based on the probability theory and normally models the underlying data using a stochastic distribution(e.g. Gaussian distribution). One of the most popular one used is \textbf{auto-regression} model or sometimes being referred as Gaussian mixture model\cite{4438332}.

\textbf{Deviation} is another way of statically outlier detection first introduced by Arning et al.\cite{A.Arning:deviation}, where an outlier is detected if feature space of one data point deviates largely from other data points. Aggarwal and YU\cite{Aggarwal:2001:ODH:375663.375668} proposed a technique for outlier detection. The basic idea in their definition is, a point is an outlier, if in some lower dimensional projection it is present in a local region of abnormally low density. This method is also an efficient method for high dimensional data set\cite{04666541}. 

Another technique introduced by Harkins et al.\cite{S.Harkins:rnn} takes advantage of replicator neutral network(RNN) to detect outliers. There might be other techniques used for unsupervised outlier detection but due to the limitation of this paper, I can not list all of them. The ones mentioned above are those best-known so far to detect outliers statically.

As modern applications have an increasing demands to process streaming data in real-time, a lot of these static methods mentioned before have been extended to work in the dynamic streaming environments. The all based on the same ideas in static approaches but algorithms have been modified in an incremental fashion to address the \textbf{concept drift} of the data stream properties.

Distance-based outlier detection approach was among the first which start to apply the method in the streaming context. In the last decade, there are several studies which focus on \textit{distance-based outlier detection in data streams(DODDS)}. Due to the fact that the distance-based require random access on the data and this is not possible with stream data, \textit{sliding window} technique was introduced which only keep a number of active objects in current window. When objects expire, they are deleted from memory as new object comes in. There are mainly two window models in data streams: count-based window and time-based window

Numerous algorithms have been invented to process stream data using sliding window on outlier detection. And based on the benchmark among all DODDS algorithms given by Luan Tran et al.\cite{Tran:2016:DOD:2994509.2994526}, the MCOD algorithm introduced by M.Kontaki et al.\cite{5767923} seems to have the most satisfying performance. Its basic idea is to pre-compute the \textit{safe inliers} that have more than $k$ neighbors which arrived after $p_{i}$ by using an event queue, which can reduce greatly on space complexity. Because the neighbors which arrives before $p_{i}$ may expire, by declaring the neighbors which arrived after $p_{i}$ to be larger than $k$, we can safely mark $p_{i}$ as inlier. The time complexity of this algorithm is guaranteed to be $O(n\log{k})$ while maintaining the space complexity to be $O(nk)$

Most of DODDS algorithms are based on the original definition of distance-based technique given by Knorr and Ng\cite{EKnorr:1998}. The other distance-based techniques in outlier detection such as KNN remain unsolved in the streaming context. It would be interested to see if those methods can be extended to work in the data streaming context. Since the these methods only have access to only a portion of data, they all lack a global view of the entire dataset and sometimes, this may affect accuracy. 

Clustering is another technique to outlier detection on stream data. Since clustering is a technique in unsupervised machine learning, it inspired the ideas of outlier detection in streaming environment. Two main algorithms exists for clustering-based approaches. One of them is called \textbf{K-Mean clustering}\cite{04666541}. It divides the stream into chunks and cluster chunks using k-mean clustering into fixed number of $k$ clusters. The mean of each clusters is calculated by metrics information of all data points in a cluster. If a data point is too far from the mean of its data point by a threshold, it will be considered as a candidate outlier. Both the \textit{mean} and the \textit{candidate outliers} detected in this chunk are carried over to next chunk in stream to further compare with data in other chunks. Other data in this chunk is simply deleted from memory. If the candidate outlier passed a given number of chunks, it is then identified as \textit{real outlier}. Compared to K-Mean clustering, \textbf{K-Median clustering}\cite{DBLP:journals/corr/abs-1002-4003} clusters each chunk of data into variable number of clusters(from $k$ to $k log(n)$), and different from K-mean clustering, it passes the weighted medians found in current chunk into next chunk for testing outlierness rather than the mean and candidate outliers. Both of these two approaches will require users' input of value $k$ but K-Median clustering theoretically is better since the number of clusters is not fixed. 

To address this problem of storage and users' input parameters, an ideal method need to find a efficient way to efficiently mine its historical data or gradually fade old data away without users' intervention. An technique inspired from \textit{sensor network} is mentioned in\cite{Subramaniam:2006:OOD:1182635.1164145}, where it use a \textbf{kernel density estimator} to model the distribution of the sensor data. When used for outlier detection, the number of neighbors of a given data point $p_{i}$ is estimated by the distribution function $f(p_{i})$. In \cite{4221341}, D. Pokrajac et al illustrated that the LOF algorithm can be applied incrementally and the insertion of new data as well as deletion of obsolete data does not depend on the total number of $N$ in dataset and therefore the time complexity of incremental LOF algorithm can theoretically be $O(N\log{N})$. These two methods are both based on computing of the \textbf{densities of local neighbourhood}. However, there are still a lot of noise around these algorithms and many researchers argue that it is still computational expensive in practice. Also the LOS approach proposed by D. Pokrajac et al will need to store the entire dataset, which is not applicable in the streaming context.

Even though there are many studies in the last decade that focusing on detecting outlier online in data stream, only a few tried to solve this problem using a parallel implementation. In \cite{7516110} C. HewaNadungodage et al.implemented a so-called SOD\_GPU\footnote{Stream Outlier Detector-GPU} algorithm which is based on kernel density estimator powered by GPU to effectively detect outlier in continuous data streams. The results seems very promising as it is 20X faster compared to a multicore CPU implementation and even a higher accuracy rate compared to the sliding window approach. And this is the only work, I found by the time of writing, which tried to solve the outlier detection problem in streaming environment using parallel computing approach. Other parallel implementations for outlier detection exist but they only work in a static fashion, in which case, it does not seem to be quite necessary. In \cite{6641405},  Angiulli et al. proposed a distance-based KNN algorithm powered by GPU and similarly, Matsumoto and Hung\cite{Matsumoto2012} introduced a GPU-accelerated approach to detect the outliers in uncertain data. Another GPU-accelerated approach to detect outlier in static data was purposed in \cite{Alshawabkeh:2010:ALO:1735688.1735707}, where the LOF(Local outlier factor) algorithm is used. Anna Koufakou et all.\cite{4634266} developed a parallel outlier detection strategy based on \textbf{Attribute Value Frequency(AVF)}\cite{4410382}\footnote{Note that the AVF algorithm can only detect outlier in categorical data.} algorithm using MapReduce programming paradigm. Other incremental parallel methods exist for online outlier detection but they either require storing the entire history of data stream or giving a set of user-defined parameters, which is hard to define in most cases. 


% ############################################################################
\section{Project Report} \label{projrep}
% ############################################################################

Present the results of your project. Add subsections as appropriate...

% ----------------------------------------------------------------------------
\subsection{Subsection 1} \label{subsect1}
% ----------------------------------------------------------------------------

...

% ----------------------------------------------------------------------------
\subsection{Subsection 2} \label{subsect2}
% ----------------------------------------------------------------------------

...

% ----------------------------------------------------------------------------
\subsection{Subsection 3} \label{subsect3}
% ----------------------------------------------------------------------------

...

You can also have figures in your paper. Figure~\ref{fig1} is a
typical example of an experimental evaluation result. Such graphs
are ususally created with GnuPlot. Figure~\ref{fig2} is an example
of a drawing created with {\em mdraw} or {\em epsfig}.

% usage: \includeFig{label}{file}{caption}

\includeFig{fig1}{Figures/figure-1}{Measured Running Times
Of Some Unknown Algorithm Implementation}

\includeFig{fig2}{Figures/figure-2}{XYZ and Hilbert Packings}




% ############################################################################
\section{Conclusion} \label{concl}
% ############################################################################

The ``moral of the story'': What have we learned? What did we achieve?
What did we not achieve? What would we do better next time? Possibilities
for future research...

% ############################################################################
% Bibliography
% ############################################################################
\bibliographystyle{plain}
\bibliography{my-bibliography}     %loads my-bibliography.bib

% ============================================================================
\end{document}
% ============================================================================
